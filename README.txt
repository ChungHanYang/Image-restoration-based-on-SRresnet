***Open this README file by Windows Notepad to get correct format!!!***
(1)Team member:Chung Han Yang 1213346041, Kuei Fang 1213351124
   Topic:Image restoration based on pretrained Generative Adversarial Network
   Member contribution:
	Kuei Fang:Implement original code, model modification, debugging
        Chung Han Yang:Implement revised part, model modification, debugging

(2)Reference paper: J. Lehtinen, J. Munkberg, J. Hasselgren, S. Laine, T. Karras, M. Aittala, and T. Aila. 
   Noise2Noise:Learning image restoration without clean data. In ICML, pages 2965–2974, 2018

(3)Github:https://github.com/shivamsaboo17/Deep-Restore-PyTorch

(4)Coco datset:http://cocodataset.org/#download(already provided in the input/train folder)

(5)Folder structure:
   ***All trained model are provided in the folder***
   -Deep Restore
       -.ideas(folder which automatically generated by pycharm)
       -__pycache__(folder which automatically generated by pycharm)
       -input
       	 -dataset
	   -test(folder which stores test data, please use one picture a time)
	   -train(folder which stores training data)
	   -valid(folder which stores validation data)
       -model_bernoulli(folder which stores trained mocel for Bernoulli noise)
       -model_Gaussian(folder which stores trainied mocel for Gaussian noise)
       -model_poisson(folder which stores trainied mocel for Poisson noise)
       -model_text(folder which stores trained mocel for text noise)
       -output(folder which stores test results)
       -data.py(python file which generates training data incuding crop and add noise)
       -drawresult.py(python file which load the trained model and draw the result)
       -README.txt
       -srresnet.py(python file which defines the structure of pretrained model we used)
       -starttrain.py(python file which train the model and define input parameters)
       -Times New Roman.ttf(file used to add text noise to the data)
       -train_utils(python file which define the training process, validation process, model saving)

(6)Adopted the pretrained model based on previous section but drop out one layer to implement image restoration.
   Trained with our own small dataset to make the model be able to restore heavily damaged images. The idea is 
   inspired by https://arxiv.org/pdf/1803.04189v3.pdf

(7)SRresnet is used to implement image super resolution which make images more clear, so we think it might be effective
   to denoise problem and it really did, we used this model and achieve acceptible results compared to the original paper which
   used Unet.

(8)Running instructions:
   -Environment:Python 3.7.3
   -Develop tool:Pycharm community 2019.1
   -Python package imported:pytorch 1.0.1, torch.nn, torch.autograd, torch.optim, torch.utils.data, tqdm, torchvision, numpy, 
                            matplotlib, os, math, random, string, sys, PIL, datatime 
   1. Open folder "RevisedCode" as a python project by pycharm
   2. Training:
      2-1 Open "starttrain.py" and type the parameter used for trainig. parameters are shown below:
          'noise_model': noise model which is added to training data, totally four models. You can type:
					     'multiplicative_bernoulli' with ratio like 0.8, 'Gaussian' with ratio like 50,
					     'text' with ratio like 0.3, 'Poisson noise' with ratio None
          'crop_size': The crop size of image. according to the papaer, best value is 64
          'clean_targs': Whether the clean target exist, default is False, no need to change
          'lr': Type the learning rate, recommand 0.005, but 0.001 for text
          'epochs': Type the number of epochs, recommand 50 for Bernoulli noise, 50 for Gaussian noise, 100 for text noise
          'bs': Type the batch size, recommand 32, but 2 for text noise(no more than 64 due to the memory of cuda)
          'lossfn': Type "l1" for l1 norm, type "l2" for MSE loss
          'cuda': Type Ture if your device supports GPU computation, otherwise, type False 
      2-2 Change the model saving directory to the corresponding one you are training at line 26 of "starttrain.py"
      2-3 Run "starttrain.py"
   3. Testing:
      3-1 Open "drawresult.py"
      3-2 Change the model directory to the one you want to show at line 16
      3-3 Change "train_noise_model" parameter at line 22 corresponds with what you typed in 2-1.	  
      3-4 Run "drawresult.py" 
	   